# -*- coding: utf-8 -*-
"""Last_round_SynBERT_Vio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V6v22cUFb3xcqr61Kvq4Uw4UqcWDnRfB
"""

import pandas as pd

# Load dataset
file_path = "/content/sqli-extended-cleaned.csv"
df_Vio = pd.read_csv(file_path)

df_Vio.head()

"""# Verify distribution"""

import matplotlib.pyplot as plt

# Count label occurrences
label_counts = df_Vio["Label"].value_counts()

plt.figure(figsize=(6,4))
label_counts.plot(kind="bar")
plt.xlabel("Label")
plt.ylabel("Count")
plt.title("Label Distribution in SQLi Dataset")
plt.show()

print(label_counts)

"""# Check the Class ratio
If Imbalance Ratio ≥ 0.5, the dataset is fairly balanced.
If Imbalance Ratio < 0.2, the dataset is highly imbalanced.
"""

count_1 = 57278
count_0 = 50163

# Compute imbalance ratio
imbalance_ratio = min(count_1, count_0) / max(count_1, count_0)

print(f"Imbalance Ratio: {imbalance_ratio:.3f}")

"""#Tokenize

This approach ensures the input data is properly formatted for model processing.

Alternatives mainly involve using AutoTokenizer for flexibility or explicitly setting padding behavior.
"""

# Import the BERT tokenizer from HuggingFace Transformers library
from transformers import BertTokenizer

# Load the pretrained SynBERT tokenizer (must match the tokenizer used during model training)
tokenizer = BertTokenizer.from_pretrained("danlou/synbert")

# Define the maximum length for tokenized sequences to ensure consistent input size
max_length = 128

# Tokenize the 'Sentence' column, ensuring padding and truncation to the max length
encodings_Vio = tokenizer(
    df_Vio["Sentence"].tolist(),     # Convert DataFrame column to a list of sentences
    truncation=True,                 # Truncate sequences longer than max_length
    padding=True,                    # Pad shorter sequences to ensure uniform input size
    max_length=max_length            # Set the maximum allowed sequence length
)

print("Tokenization complete!")

"""# Convert to Pytorch"""

import torch

# Convert tokenized input IDs to PyTorch tensors for model processing
input_ids_Vio = torch.tensor(encodings_Vio["input_ids"])
# Why: The model expects inputs as tensors for efficient computation.
# Alternative: TensorFlow

# Convert attention masks to PyTorch tensors
attention_mask_Vio = torch.tensor(encodings_Vio["attention_mask"])
# Why: Attention masks indicate which tokens are actual input (1) and which are padding (0).
# Alternative: TensorFlow

# Convert labels to PyTorch tensors
labels_Vio = torch.tensor(df_Vio["Label"].tolist())
# Why: Labels are needed for supervised learning during model training.

print("\nTokenized Example:")
print(input_ids_Vio[:2])

"""# Create tensors in dataset"""

# Import classes for handling datasets and loading them in batches
from torch.utils.data import TensorDataset, DataLoader

# Combine input tensors into a single dataset object
violetas_dataset = TensorDataset(input_ids_Vio, attention_mask_Vio, labels_Vio)
# Why: This groups input IDs, attention masks, and labels together, allowing for easy batch processing.
# Alternative: Use `torch.utils.data.Dataset` for more customized dataset handling if additional preprocessing is needed.

# Define batch size for training or evaluation
batch_size = 32

print(f"\nNew dataset is ready with {len(violetas_dataset)} samples.")

"""# Split the data"""

from torch.utils.data import TensorDataset, random_split

# Combine input tensors into a dataset
dataset_Violeta = TensorDataset(input_ids_Vio, attention_mask_Vio, labels_Vio)

# Define split size
train_size = int(0.6 * len(dataset_Violeta))
val_size = int(0.2 * len(dataset_Violeta))
test_size = len(dataset_Violeta) - train_size - val_size

# Split
train_dataset, val_dataset, test_dataset = random_split(dataset_Violeta, [train_size, val_size, test_size])

print(f"Training set: {len(train_dataset)} samples")
print(f"Validation set: {len(val_dataset)} samples")
print(f"Testing set: {len(test_dataset)} samples")

"""# Create dataloaders"""

# Create DataLoader for the training dataset with shuffling enabled
train_dataloader = DataLoader(
    train_dataset,    # Dataset used for training
    shuffle=True,     # Shuffling helps the model generalize better by avoiding learning the order of data
    batch_size=batch_size  # Number of samples per batch
)

# Create DataLoader for the validation dataset without shuffling.
# Validation ant testing data should not be shuffled to ensure consistent metrics.
val_dataloader = DataLoader(
    val_dataset,      # Dataset used for model validation
    shuffle=False,    # No shuffling to ensure consistent evaluation
    batch_size=batch_size
)

# Create DataLoader for the testing dataset without shuffling
test_dataloader = DataLoader(
    test_dataset,     # Dataset used for final model evaluation
    shuffle=False,    # No shuffling ensures reproducible results
    batch_size=batch_size
)

print(f"Training batches: {len(train_dataloader)}")
print(f"Validation batches: {len(val_dataloader)}")
print(f"Testing batches: {len(test_dataloader)}")

"""# Load pretrained synBert"""

from transformers import BertForSequenceClassification

model = BertForSequenceClassification.from_pretrained("danlou/synbert", num_labels=2)

# Move model to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

print(f"Model loaded on: {device}")

"""# Set up optimizer AdamW"""

# Import the AdamW optimizer (Adam with Weight Decay) from PyTorch
from torch.optim import AdamW

# Import the learning rate scheduler helper from HuggingFace
from transformers import get_scheduler

# Initialize the AdamW optimizer with model parameters
optimizer = AdamW(
    model.parameters(),  # Parameters of the model to optimize
    lr=2e-5,             # Learning rate, a common default for fine-tuning BERT
    eps=1e-8             # Epsilon to prevent division by zero in optimizer updates
)
# Why: AdamW is preferred for transformers as it handles weight decay better than the traditional Adam optimizer.

# Calculate total training steps (number of batches per epoch * number of epochs)
num_training_steps = len(train_dataloader) * 10
# Why: Required to define the total length of the learning rate schedule.

# Set up a learning rate scheduler with linear decay
lr_scheduler = get_scheduler(
    name="linear",               # Linear scheduler reduces the learning rate linearly over time
    optimizer=optimizer,         # Optimizer to apply the scheduler to
    num_warmup_steps=0,          # Number of steps for gradual warm-up (can improve model stability if set >0)
    num_training_steps=num_training_steps  # Total number of training steps
)
# Why: Helps in gradually reducing the learning rate, improving convergence.

# Define the loss function (CrossEntropy is standard for classification tasks)
loss_fn = torch.nn.CrossEntropyLoss()

print(f"Optimizer: AdamW, Learning Rate: 2e-5")
print(f"Total Training Steps: {num_training_steps}")

"""## Early Stopping, to prevent overfitting, if validation loss stops improving"""

# Import NumPy for numerical operations
import numpy as np

class EarlyStopping:
    def __init__(self, patience=5, delta=0, path='best_model.pt', verbose=False):
        self.patience = patience  # Number of epochs to wait after no improvement
        self.delta = delta        # Minimum change in loss to qualify as an improvement
        self.path = path          # File path to save the best model
        self.verbose = verbose    # Whether to print messages during training
        self.counter = 0          # Counter to track epochs without improvement
        self.best_loss = np.inf   # Initialize best loss to infinity
        self.early_stop = False   # Flag to indicate whether to stop early

    # Method to be used during training
    def __call__(self, val_loss, model):
        # Check if the current validation loss is an improvement
        if val_loss < self.best_loss - self.delta:
            self.best_loss = val_loss          # Update best loss
            self.save_checkpoint(model)        # Save the improved model
            self.counter = 0                   # Reset the counter
        else:
            self.counter += 1                  # Increment counter if no improvement
            if self.verbose:
                # Print counter status if verbose mode is on
                print(f"EarlyStopping counter: {self.counter} out of {self.patience}")
            # Check if the patience limit has been reached
            if self.counter >= self.patience:
                self.early_stop = True         # Trigger early stopping

    # Method to save the current model
    def save_checkpoint(self, model):
        if self.verbose:
            # Print a message when saving the model
            print(f"Validation loss decreased. Saving model to {self.path}")
        # Save the model’s state_dict to the specified path
        torch.save(model.state_dict(), self.path)

"""## Training and validation function"""

import torch.nn.functional as F  # Provides common functions like activation and loss functions
from torch.utils.data import DataLoader  # Handles batching and shuffling of datasets
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # Metrics for model evaluation
import json  # To handle JSON data if needed for output
import seaborn as sns  # Visualization library for plots like confusion matrices
import matplotlib.pyplot as plt  # Basic plotting library
from sklearn.model_selection import cross_val_score, StratifiedKFold  # For cross-validation
from tqdm import tqdm  # For progress bars during training loops

def train_and_validate(model, train_dataloader, val_dataloader, optimizer, loss_fn, lr_scheduler, epochs, device):
    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []

    # Initialize EarlyStopping
    early_stopping = EarlyStopping(patience=3, verbose=True)

    # Loop over each epoch
    for epoch in range(epochs):
        # Set the model to training mode
        model.train()
        train_loss, train_correct = 0, 0  # Reset training loss and correct count for the epoch

        # Iterate through batches in the training DataLoader
        for batch in tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{epochs} - Training"):
            # Move input_ids, attention_mask, and labels to the specified device (e.g., GPU)
            input_ids, attention_mask, labels = [x.to(device) for x in batch]
            # Reset gradients before backpropagation
            optimizer.zero_grad()
            # Forward pass through the model
            outputs = model(input_ids, attention_mask=attention_mask)
            # Compute loss between model predictions and true labels
            loss = loss_fn(outputs.logits, labels)
            # Backpropagate the loss
            loss.backward()
            # Update model weights
            optimizer.step()
            # Update learning rate using the scheduler
            lr_scheduler.step()
            # Accumulate total training loss
            train_loss += loss.item()
            # Count how many predictions are correct
            train_correct += (outputs.logits.argmax(dim=1) == labels).sum().item()

        # Store average training loss for the epoch
        train_losses.append(train_loss / len(train_dataloader))
        # Store training accuracy for the epoch
        train_accuracies.append(train_correct / len(train_dataloader.dataset))

        # Set the model to evaluation mode for validation
        model.eval()
        val_loss, val_correct = 0, 0  # Reset validation loss and correct count

        # Disable gradient computation for validation
        with torch.no_grad():
            # Iterate through batches in the validation DataLoader
            for batch in tqdm(val_dataloader, desc=f"Epoch {epoch+1}/{epochs} - Validation"):
                # Move inputs and labels to the device
                input_ids, attention_mask, labels = [x.to(device) for x in batch]
                # Forward pass
                outputs = model(input_ids, attention_mask=attention_mask)
                # Compute loss
                loss = loss_fn(outputs.logits, labels)
                # Accumulate validation loss
                val_loss += loss.item()
                # Count correct predictions
                val_correct += (outputs.logits.argmax(dim=1) == labels).sum().item()

        # Store average validation loss for the epoch
        val_losses.append(val_loss / len(val_dataloader))
        # Store validation accuracy for the epoch
        val_accuracies.append(val_correct / len(val_dataloader.dataset))

        # Print training and validation performance for this epoch
        print(f"Epoch {epoch+1}: Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f}, "
              f"Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.4f}")

        # Check if early stopping should be triggered based on validation loss
        early_stopping(val_losses[-1], model)

        # If early stopping criterion met, break out of training loop
        if early_stopping.early_stop:
            print("Early stopping triggered! Stopping training...")
            break

    # Load the model weights from the best saved checkpoint
    model.load_state_dict(torch.load('best_model.pt'))

    return train_losses, train_accuracies, val_losses, val_accuracies

"""## Run training and save training and validation results"""

import pandas as pd
import matplotlib.pyplot as plt

# Training and validation process
train_losses, train_accuracies, val_losses, val_accuracies = train_and_validate(
    model, train_dataloader, val_dataloader, optimizer, loss_fn, lr_scheduler, epochs=10, device=device
)
# Save Results as a CSV
results_df = pd.DataFrame({
    'Epoch': list(range(1, len(train_losses) + 1)),
    'Train Loss': train_losses,
    'Train Accuracy': train_accuracies,
    'Validation Loss': val_losses,
    'Validation Accuracy': val_accuracies
})
results_df.to_csv('training_results.csv', index=False)
print("Training and validation results saved to 'training_results.csv'.")

"""# Evaluation"""

import torch
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix

# Define a function to evaluate and save model results
def evaluate_model(model, test_dataloader, device, output_prefix="model"):
    model.eval()
    y_true, y_pred, prob_positive = [], [], []

    with torch.no_grad():
        for batch in test_dataloader:
            input_ids, attention_mask, labels = [x.to(device) for x in batch]

            # Get model outputs
            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits

            # Predictions and probabilities
            probs = torch.softmax(logits, dim=1)  # get class probabilities
            predictions = logits.argmax(dim=1).cpu().numpy()
            positive_probs = probs[:, 1].cpu().numpy()  # probability of class 1

            y_pred.extend(predictions)
            y_true.extend(labels.cpu().numpy())
            prob_positive.extend(positive_probs)

    # Generate classification report and confusion matrix
    report = classification_report(y_true, y_pred, output_dict=True)
    conf_matrix = confusion_matrix(y_true, y_pred)

    # Save predictions
    df_preds = pd.DataFrame({
        "Actual": y_true,
        "Predicted": y_pred,
        "Prob_Positive": prob_positive
    })
    df_preds.to_csv(f"{output_prefix}_predictions.csv", index=False)

    # Save classification report
    report_df = pd.DataFrame(report).transpose()
    report_df.to_csv(f"{output_prefix}_classification_report.csv")

    # Save confusion matrix
    conf_matrix_df = pd.DataFrame(conf_matrix)
    conf_matrix_df.to_csv(f"{output_prefix}_confusion_matrix.csv", index=False)

    print(f"Saved predictions, report, and confusion matrix as '{output_prefix}_*.csv'")
    return report, conf_matrix

report, matrix = evaluate_model(model, test_dataloader, device, output_prefix="vio_final")

"""# Save model"""

# Save entire model
torch.save(model, "synbert_last_on_Vio.pth")
print("Model saved ")

torch.save(model, "synbert_last_on_Vio.pth")

from google.colab import files
files.download("synbert_last_on_Vio.pth")
print("Model downloaded to Mac.")

from google.colab import drive
drive.mount('/content/drive')

drive_path = "/content/drive/My Drive/models_5/synbert_model.pth"

# Ensure the directory exists
os.makedirs(os.path.dirname(drive_path), exist_ok=True)

# Save the model
torch.save(model, drive_path)
print(f" Model saved to Google Drive at {drive_path}")

"""# RELOAD MODEL"""

import torch

model_path = "synbert_last_on_Vio.pth"

# Trust the file — override PyTorch's default restriction
model = torch.load(model_path, map_location="cpu", weights_only=False)

# Move to device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

print("Model loaded and ready for testing!")

"""# Evaluate on Sahands DS (Dataset_A)


"""

import pandas as pd

file_path = "/content/sahand_dataset_cleaned.csv"

with open(file_path, "r") as file:
  for i in range(10):
    print(file.readline().strip())

df_Sah = pd.read_csv(file_path)

print(df_Sah.head)

"""# Tokenize"""

print ("\nDataset Ifo:")
print(df_Sah.info())

df_Sah = df_Sah.dropna()

from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained("danlou/synbert")

max_length = 128
encodings_Sah = tokenizer(df_Sah["Query"].tolist(), truncation=True, padding=True, max_length=max_length)

"""# Convert ti PyTorch"""

import torch

input_ids_Sah = torch.tensor(encodings_Sah["input_ids"])
attention_mask = torch.tensor(encodings_Sah["attention_mask"])
labels_Sah = torch.tensor(df_Sah["Label"].tolist())

print("\nTokenized Example:")
print(input_ids_Sah[:2])

"""# Combine into datasets"""

import torch
from torch.utils.data import TensorDataset, DataLoader

sah_dataset = TensorDataset(input_ids_Sah, attention_mask, labels_Sah)

# Create Dataloader
batch_size = 16
sah_dataloader = DataLoader(sah_dataset, batch_size=batch_size, shuffle=False)

print(f"\nNew dataset is ready with {len(sah_dataset)} samples.")

"""# Evaluate"""

import json
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix

# Enhanced evaluation for unseen dataset
def evaluate_model_on_unseen(model, dataloader, device, output_prefix="sah"):
    model.eval()
    y_true, y_pred, prob_positive = [], [], []

    with torch.no_grad():
        for batch in dataloader:
            input_ids, attention_mask, labels = [x.to(device) for x in batch]
            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=1)
            predictions = logits.argmax(dim=1).cpu().numpy()
            positive_probs = probs[:, 1].cpu().numpy()

            y_pred.extend(predictions)
            y_true.extend(labels.cpu().numpy())
            prob_positive.extend(positive_probs)

    # Create predictions DataFrame and save
    df_preds = pd.DataFrame({
        "Actual": y_true,
        "Predicted": y_pred,
        "Prob_Positive": prob_positive
    })
    df_preds.to_csv(f"{output_prefix}_predictions.csv", index=False)
    print(f"Predictions saved to {output_prefix}_predictions.csv")

    # Generate classification report and confusion matrix
    report = classification_report(y_true, y_pred, output_dict=True)
    conf_matrix = confusion_matrix(y_true, y_pred)

    # Save classification report as CSV and JSON
    pd.DataFrame(report).transpose().to_csv(f"{output_prefix}_classification_report.csv")
    with open(f"{output_prefix}_classification_report.json", "w") as json_file:
        json.dump(report, json_file, indent=4)
    print(f"Classification report saved to {output_prefix}_classification_report.(csv/json)")

    # Save confusion matrix as CSV
    pd.DataFrame(conf_matrix).to_csv(f"{output_prefix}_confusion_matrix.csv", index=False)
    print(f"Confusion matrix saved to {output_prefix}_confusion_matrix.csv")

    # Save confusion matrix as heatmap image
    plt.figure(figsize=(6, 5))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Confusion Matrix - {output_prefix.upper()} Dataset")
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.tight_layout()
    plt.savefig(f"{output_prefix}_confusion_matrix.png")
    print(f"Confusion matrix image saved to {output_prefix}_confusion_matrix.png")
    plt.show()

    return report, conf_matrix

report, conf_matrix = evaluate_model_on_unseen(model, sah_dataloader, device, output_prefix="sah")

"""# Evaluate on Jonathans"""

import pandas as pd

file_path = "/content/jonathans_dataset.csv"

# Open and print the first few lines
with open(file_path, "r", encoding="ascii", errors="replace") as file:
    for i in range(10):
        print(file.readline().strip())

import pandas as pd

# Load the dataset using the correct separator
df_Jon = pd.read_csv(file_path, sep=";", encoding="ascii")

"""# Tokenize"""

from transformers import BertTokenizer
import torch

# Load the trained tokenizer (same as used during training)
tokenizer = BertTokenizer.from_pretrained("danlou/synbert")

# Tokenize the SQL queries from Jonathan's dataset
max_length = 128
encodings_Jon = tokenizer(df_Jon["Query"].tolist(), truncation=True, padding=True, max_length=max_length)

# Convert to PyTorch tensors
input_ids_Jon = torch.tensor(encodings_Jon["input_ids"])
attention_mask_Jon = torch.tensor(encodings_Jon["attention_mask"])
labels_Jon = torch.tensor(df_Jon["Label"].tolist())

print(" Tokenization complete!")

"""# Dataloaders"""

from torch.utils.data import TensorDataset, DataLoader

# Create a PyTorch dataset
jonathan_dataset = TensorDataset(input_ids_Jon, attention_mask_Jon, labels_Jon)

# Create DataLoader
batch_size = 16
jonathan_dataloader = DataLoader(jonathan_dataset, batch_size=batch_size, shuffle=False)

print(f"Testing dataset ready with {len(jonathan_dataset)} samples.")

"""# Evaluate"""

import json
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix

def evaluate_model_on_unseen_jon(model, dataloader, device, output_prefix="jon"):
    model.eval()
    y_true, y_pred, prob_positive = [], [], []

    with torch.no_grad():
        for batch in dataloader:
            input_ids, attention_mask, labels = [x.to(device) for x in batch]
            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=1)
            predictions = logits.argmax(dim=1).cpu().numpy()
            positive_probs = probs[:, 1].cpu().numpy()

            y_pred.extend(predictions)
            y_true.extend(labels.cpu().numpy())
            prob_positive.extend(positive_probs)

    # Save predictions CSV
    df_preds = pd.DataFrame({
        "Actual": y_true,
        "Predicted": y_pred,
        "Prob_Positive": prob_positive
    })
    df_preds.to_csv(f"{output_prefix}_predictions.csv", index=False)
    print(f"Predictions saved to {output_prefix}_predictions.csv")

    # Classification report
    report = classification_report(y_true, y_pred, output_dict=True)
    pd.DataFrame(report).transpose().to_csv(f"{output_prefix}_classification_report.csv")
    with open(f"{output_prefix}_classification_report.json", "w") as json_file:
        json.dump(report, json_file, indent=4)
    print(f"Classification report saved to {output_prefix}_classification_report.(csv/json)")

    # Confusion matrix
    conf_matrix = confusion_matrix(y_true, y_pred)
    pd.DataFrame(conf_matrix).to_csv(f"{output_prefix}_confusion_matrix.csv", index=False)
    print(f"Confusion matrix saved to {output_prefix}_confusion_matrix.csv")

    # Confusion matrix heatmap
    plt.figure(figsize=(6, 5))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Confusion Matrix - {output_prefix.upper()} Dataset")
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.tight_layout()
    plt.savefig(f"{output_prefix}_confusion_matrix.png")
    print(f"Confusion matrix image saved to {output_prefix}_confusion_matrix.png")
    plt.show()

    return report, conf_matrix

report, conf_matrix = evaluate_model_on_unseen_jon(model, jonathan_dataloader, device, output_prefix="jon")

report, conf_matrix = evaluate_model_on_unseen_jon(model, jon_dataloader, device)

"""# Tested VIO 20% (Daraset_C)"""

import pandas as pd
from IPython.display import display

# Load classification report
report_df = pd.read_csv("vio_final_classification_report.csv", index_col=0)
print("Classification Report:")
display(report_df)

# Load confusion matrix
conf_matrix_df = pd.read_csv("vio_final_confusion_matrix.csv")
conf_matrix_df.columns = [f"Predicted {i}" for i in range(conf_matrix_df.shape[1])]
conf_matrix_df.index = [f"Actual {i}" for i in range(conf_matrix_df.shape[0])]
print("Confusion Matrix:")
display(conf_matrix_df)

"""# Tested on Jonathans"""

import pandas as pd
from IPython.display import display

# Load classification report
report_df = pd.read_csv("jon_classification_report.csv", index_col=0)
print("Classification Report:")
display(report_df)

# Load confusion matrix
conf_matrix_df = pd.read_csv("jon_confusion_matrix.csv")
conf_matrix_df.columns = [f"Predicted {i}" for i in range(conf_matrix_df.shape[1])]
conf_matrix_df.index = [f"Actual {i}" for i in range(conf_matrix_df.shape[0])]
print("Confusion Matrix:")
display(conf_matrix_df)

"""# Tested on Sahands"""

import pandas as pd
from IPython.display import display

# Load classification report
report_df = pd.read_csv("sah_classification_report.csv", index_col=0)
print("Classification Report:")
display(report_df)

# Load confusion matrix
conf_matrix_df = pd.read_csv("sah_confusion_matrix.csv")
conf_matrix_df.columns = [f"Predicted {i}" for i in range(conf_matrix_df.shape[1])]
conf_matrix_df.index = [f"Actual {i}" for i in range(conf_matrix_df.shape[0])]
print("Confusion Matrix:")
display(conf_matrix_df)













π













